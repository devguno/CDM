{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in C://extract_pc2:\n",
      "\n",
      "Only in F://extract_pc2:\n",
      "202103_167_75399401.SIG\n",
      "202103_166_75399401.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 두 경로 설정\n",
    "path1 = \"C://extract_pc2\"\n",
    "path2 = \"F://extract_pc2\"\n",
    "\n",
    "# 경로에서 파일 목록을 가져오는 함수\n",
    "def get_files_in_directory(path):\n",
    "    files = []\n",
    "    for root, dirs, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            files.append(os.path.relpath(os.path.join(root, filename), path))\n",
    "    return set(files)\n",
    "\n",
    "# 각 경로에서 파일 목록 가져오기\n",
    "files_in_path1 = get_files_in_directory(path1)\n",
    "files_in_path2 = get_files_in_directory(path2)\n",
    "\n",
    "# 한쪽 경로에만 있는 파일 찾기\n",
    "only_in_path1 = files_in_path1 - files_in_path2\n",
    "only_in_path2 = files_in_path2 - files_in_path1\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Only in {path1}:\")\n",
    "for file in only_in_path1:\n",
    "    print(file)\n",
    "\n",
    "print(f\"\\nOnly in {path2}:\")\n",
    "for file in only_in_path2:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매칭되지 않은 건수: 67\n",
      "person_id 컬럼이 추가된 EPS.csv 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# EPS.csv 파일 불러오기\n",
    "eps_df = pd.read_csv(r'C:\\Users\\SNUH\\Desktop\\EPS.csv', encoding='cp949')\n",
    "\n",
    "# holter_pid_202409091527.csv 파일 불러오기\n",
    "holter_df = pd.read_csv(r'C:\\Users\\SNUH\\holter_pid_202409091527.csv')\n",
    "\n",
    "# 두 데이터프레임을 id (EPS)와 pt_no (holter) 기준으로 병합 (left join)\n",
    "merged_df = pd.merge(eps_df, holter_df[['pt_no', 'person_id']], left_on='id', right_on='pt_no', how='left')\n",
    "\n",
    "# 병합된 데이터프레임에서 필요한 person_id 컬럼만 추가\n",
    "eps_df['person_id'] = merged_df['person_id']\n",
    "\n",
    "# 매칭되지 않은 데이터 (person_id가 NaN인 행) 확인\n",
    "unmatched_count = eps_df['person_id'].isna().sum()\n",
    "\n",
    "# 결과를 EPS_with_person_id.csv 파일에 다시 저장\n",
    "eps_df.to_csv(r'C:\\Users\\SNUH\\Desktop\\EPS_with_person_id.csv', encoding='cp949', index=False)\n",
    "\n",
    "print(f\"매칭되지 않은 건수: {unmatched_count}\")\n",
    "print(\"person_id 컬럼이 추가된 EPS.csv 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매칭되지 않은 건수: 47\n",
      "person_id 컬럼이 추가된 EPS.csv 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# EPS.csv 파일 불러오기\n",
    "eps_df = pd.read_csv(r'C:\\Users\\SNUH\\Desktop\\EPS(without CHD, WPW,CMP).csv', encoding='cp949')\n",
    "\n",
    "# holter_pid_202409091527.csv 파일 불러오기\n",
    "holter_df = pd.read_csv(r'C:\\Users\\SNUH\\holter_pid_202409091527.csv')\n",
    "\n",
    "# 두 데이터프레임을 id (EPS)와 pt_no (holter) 기준으로 병합 (left join)\n",
    "merged_df = pd.merge(eps_df, holter_df[['pt_no', 'person_id']], left_on='id', right_on='pt_no', how='left')\n",
    "\n",
    "# 병합된 데이터프레임에서 필요한 person_id 컬럼만 추가\n",
    "eps_df['person_id'] = merged_df['person_id']\n",
    "\n",
    "# 매칭되지 않은 데이터 (person_id가 NaN인 행) 확인\n",
    "unmatched_count = eps_df['person_id'].isna().sum()\n",
    "\n",
    "# 결과를 EPS_with_person_id.csv 파일에 다시 저장\n",
    "eps_df.to_csv(r'C:\\Users\\SNUH\\Desktop\\EPS(without CHD, WPW,CMP)_with_person_id.csv', encoding='cp949', index=False)\n",
    "\n",
    "print(f\"매칭되지 않은 건수: {unmatched_count}\")\n",
    "print(\"person_id 컬럼이 추가된 EPS.csv 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매칭되지 않은 건수: 0\n",
      "person_id 컬럼이 추가된 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# EPS.csv 파일 불러오기\n",
    "eps_df = pd.read_csv(r'C:\\Users\\SNUH\\Desktop\\holter_data_pt_.csv')\n",
    "\n",
    "# holter_pid_202409091527.csv 파일 불러오기\n",
    "holter_df = pd.read_csv(r'C:\\Users\\SNUH\\OneDrive\\SNUH BMI Lab\\CDM\\Holter\\pid\\pt_no_person_id.csv')\n",
    "\n",
    "# 두 데이터프레임을 id (EPS)와 pt_no (holter) 기준으로 병합 (left join)\n",
    "merged_df = pd.merge(eps_df, holter_df[['pt_no', 'person_id']], left_on='pt_no', right_on='pt_no', how='left')\n",
    "\n",
    "# 병합된 데이터프레임에서 필요한 person_id 컬럼만 추가\n",
    "eps_df['person_id'] = merged_df['person_id']\n",
    "\n",
    "# 매칭되지 않은 데이터 (person_id가 NaN인 행) 확인\n",
    "unmatched_count = eps_df['person_id'].isna().sum()\n",
    "\n",
    "# 결과를 EPS_with_person_id.csv 파일에 다시 저장\n",
    "eps_df.to_csv(r'C:\\Users\\SNUH\\Desktop\\holter_data.csv', index=False)\n",
    "\n",
    "print(f\"매칭되지 않은 건수: {unmatched_count}\")\n",
    "print(\"person_id 컬럼이 추가된 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patient_info': {'PID': '35060635', 'HookupDate': '2016-04-11', 'HookupTime': '09:44:00'}, 'summary': {'HR':     Hour  Min  #QRS's  Min.  Ave.  Max.  Pauses\n",
      "0      9   16    1197    60    75    87       0\n",
      "1     10   60    4232    54    71    92       0\n",
      "2     11   60    4406    60    73    91       0\n",
      "3     12   60    4436    62    74    89       0\n",
      "4     13   60    4107    55    68    85       0\n",
      "5     14   60    4263    56    71    86       0\n",
      "6     15   60    3895    53    65    87       0\n",
      "7     16   60    4009    55    67    87       0\n",
      "8     17   60    3943    51    66    84       0\n",
      "9     18   60    4025    51    67    86       0\n",
      "10    19   60    4161    54    69    89       0\n",
      "11    20   60    3764    53    63    80       0\n",
      "12    21   60    3595    50    60    80       0\n",
      "13    22   60    3367    50    56    80       0\n",
      "14    23   60    3446    49    57    79       0\n",
      "15     0   60    3356    49    56    72       0\n",
      "16     1   60    3475    49    58    89       0\n",
      "17     2   60    3321    49    55    74       0\n",
      "18     3   60    3366    49    56    85       0\n",
      "19     4   60    3422    49    57    83       0\n",
      "20     5   60    3352    49    56    83       0\n",
      "21     6   60    3413    49    57    83       0\n",
      "22     7   60    4008    52    67    90       0\n",
      "23     8   43    3163    57    74    96       0, 'VT':     Hour  Min  V_Iso  V_Cplt  V_Runs  V_Max_Run  V_Max_Rate\n",
      "0      9   16    264       0       0          0           0\n",
      "1     10   60   1022       0       0          0           0\n",
      "2     11   60   1042       1       0          0           0\n",
      "3     12   60   1124       0       0          0           0\n",
      "4     13   60   1080       0       0          0           0\n",
      "5     14   60   1084       0       0          0           0\n",
      "6     15   60   1050       0       0          0           0\n",
      "7     16   60    669       0       0          0           0\n",
      "8     17   60    513       0       0          0           0\n",
      "9     18   60    940       0       0          0           0\n",
      "10    19   60   1130       0       0          0           0\n",
      "11    20   60    760       0       0          0           0\n",
      "12    21   60    169       0       0          0           0\n",
      "13    22   60    130       0       0          0           0\n",
      "14    23   60    164       0       0          0           0\n",
      "15     0   60    210       0       0          0           0\n",
      "16     1   60    139       0       0          0           0\n",
      "17     2   60    175       1       0          0           0\n",
      "18     3   60    214       0       0          0           0\n",
      "19     4   60    160       0       0          0           0\n",
      "20     5   60    101       0       0          0           0\n",
      "21     6   60    120       0       0          0           0\n",
      "22     7   60     79       0       0          0           0\n",
      "23     8   43    226       0       0          0           0, 'SVT':     Hour  Min  S_Iso  S_Cplt  S_Runs  S_Max_Run  S_Max_Rate\n",
      "0      9   16      0       0       0          0           0\n",
      "1     10   60      0       0       0          0           0\n",
      "2     11   60      2       0       0          0           0\n",
      "3     12   60      0       0       0          0           0\n",
      "4     13   60      1       0       0          0           0\n",
      "5     14   60      0       0       0          0           0\n",
      "6     15   60      0       1       0          0           0\n",
      "7     16   60      0       0       0          0           0\n",
      "8     17   60      3       0       0          0           0\n",
      "9     18   60      0       0       0          0           0\n",
      "10    19   60      0       0       0          0           0\n",
      "11    20   60      0       0       0          0           0\n",
      "12    21   60      1       0       0          0           0\n",
      "13    22   60      1       0       0          0           0\n",
      "14    23   60      2       1       0          0           0\n",
      "15     0   60      0       0       0          0           0\n",
      "16     1   60      2       0       0          0           0\n",
      "17     2   60      0       0       0          0           0\n",
      "18     3   60      0       0       0          0           0\n",
      "19     4   60      0       0       0          0           0\n",
      "20     5   60      3       0       0          0           0\n",
      "21     6   60      1       0       0          0           0\n",
      "22     7   60      3       0       0          0           0\n",
      "23     8   43      2       0       0          0           0}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Path to the pickle file\n",
    "pickle_file_path = r'D:\\test\\2224_143_35060635.pickle'\n",
    "\n",
    "# Open the pickle file and load the data\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Now 'data' holds the deserialized content of the pickle file\n",
    "print(data)  # You can print or further manipulate 'data'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
