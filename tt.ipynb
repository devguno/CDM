{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in C://extract_pc2:\n",
      "\n",
      "Only in F://extract_pc2:\n",
      "202103_167_75399401.SIG\n",
      "202103_166_75399401.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 두 경로 설정\n",
    "path1 = \"C://extract_pc2\"\n",
    "path2 = \"F://extract_pc2\"\n",
    "\n",
    "# 경로에서 파일 목록을 가져오는 함수\n",
    "def get_files_in_directory(path):\n",
    "    files = []\n",
    "    for root, dirs, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            files.append(os.path.relpath(os.path.join(root, filename), path))\n",
    "    return set(files)\n",
    "\n",
    "# 각 경로에서 파일 목록 가져오기\n",
    "files_in_path1 = get_files_in_directory(path1)\n",
    "files_in_path2 = get_files_in_directory(path2)\n",
    "\n",
    "# 한쪽 경로에만 있는 파일 찾기\n",
    "only_in_path1 = files_in_path1 - files_in_path2\n",
    "only_in_path2 = files_in_path2 - files_in_path1\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Only in {path1}:\")\n",
    "for file in only_in_path1:\n",
    "    print(file)\n",
    "\n",
    "print(f\"\\nOnly in {path2}:\")\n",
    "for file in only_in_path2:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매칭되지 않은 건수: 67\n",
      "person_id 컬럼이 추가된 EPS.csv 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# EPS.csv 파일 불러오기\n",
    "eps_df = pd.read_csv(r'C:\\Users\\SNUH\\Desktop\\EPS.csv', encoding='cp949')\n",
    "\n",
    "# holter_pid_202409091527.csv 파일 불러오기\n",
    "holter_df = pd.read_csv(r'C:\\Users\\SNUH\\holter_pid_202409091527.csv')\n",
    "\n",
    "# 두 데이터프레임을 id (EPS)와 pt_no (holter) 기준으로 병합 (left join)\n",
    "merged_df = pd.merge(eps_df, holter_df[['pt_no', 'person_id']], left_on='id', right_on='pt_no', how='left')\n",
    "\n",
    "# 병합된 데이터프레임에서 필요한 person_id 컬럼만 추가\n",
    "eps_df['person_id'] = merged_df['person_id']\n",
    "\n",
    "# 매칭되지 않은 데이터 (person_id가 NaN인 행) 확인\n",
    "unmatched_count = eps_df['person_id'].isna().sum()\n",
    "\n",
    "# 결과를 EPS_with_person_id.csv 파일에 다시 저장\n",
    "eps_df.to_csv(r'C:\\Users\\SNUH\\Desktop\\EPS_with_person_id.csv', encoding='cp949', index=False)\n",
    "\n",
    "print(f\"매칭되지 않은 건수: {unmatched_count}\")\n",
    "print(\"person_id 컬럼이 추가된 EPS.csv 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매칭되지 않은 건수: 47\n",
      "person_id 컬럼이 추가된 EPS.csv 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# EPS.csv 파일 불러오기\n",
    "eps_df = pd.read_csv(r'C:\\Users\\SNUH\\Desktop\\EPS(without CHD, WPW,CMP).csv', encoding='cp949')\n",
    "\n",
    "# holter_pid_202409091527.csv 파일 불러오기\n",
    "holter_df = pd.read_csv(r'C:\\Users\\SNUH\\holter_pid_202409091527.csv')\n",
    "\n",
    "# 두 데이터프레임을 id (EPS)와 pt_no (holter) 기준으로 병합 (left join)\n",
    "merged_df = pd.merge(eps_df, holter_df[['pt_no', 'person_id']], left_on='id', right_on='pt_no', how='left')\n",
    "\n",
    "# 병합된 데이터프레임에서 필요한 person_id 컬럼만 추가\n",
    "eps_df['person_id'] = merged_df['person_id']\n",
    "\n",
    "# 매칭되지 않은 데이터 (person_id가 NaN인 행) 확인\n",
    "unmatched_count = eps_df['person_id'].isna().sum()\n",
    "\n",
    "# 결과를 EPS_with_person_id.csv 파일에 다시 저장\n",
    "eps_df.to_csv(r'C:\\Users\\SNUH\\Desktop\\EPS(without CHD, WPW,CMP)_with_person_id.csv', encoding='cp949', index=False)\n",
    "\n",
    "print(f\"매칭되지 않은 건수: {unmatched_count}\")\n",
    "print(\"person_id 컬럼이 추가된 EPS.csv 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매칭되지 않은 건수: 0\n",
      "person_id 컬럼이 추가된 파일이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# EPS.csv 파일 불러오기\n",
    "eps_df = pd.read_csv(r'C:\\Users\\SNUH\\Desktop\\holter_data_pt_.csv')\n",
    "\n",
    "# holter_pid_202409091527.csv 파일 불러오기\n",
    "holter_df = pd.read_csv(r'C:\\Users\\SNUH\\OneDrive\\SNUH BMI Lab\\CDM\\Holter\\pid\\pt_no_person_id.csv')\n",
    "\n",
    "# 두 데이터프레임을 id (EPS)와 pt_no (holter) 기준으로 병합 (left join)\n",
    "merged_df = pd.merge(eps_df, holter_df[['pt_no', 'person_id']], left_on='pt_no', right_on='pt_no', how='left')\n",
    "\n",
    "# 병합된 데이터프레임에서 필요한 person_id 컬럼만 추가\n",
    "eps_df['person_id'] = merged_df['person_id']\n",
    "\n",
    "# 매칭되지 않은 데이터 (person_id가 NaN인 행) 확인\n",
    "unmatched_count = eps_df['person_id'].isna().sum()\n",
    "\n",
    "# 결과를 EPS_with_person_id.csv 파일에 다시 저장\n",
    "eps_df.to_csv(r'C:\\Users\\SNUH\\Desktop\\holter_data.csv', index=False)\n",
    "\n",
    "print(f\"매칭되지 않은 건수: {unmatched_count}\")\n",
    "print(\"person_id 컬럼이 추가된 파일이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patient_info': {'PID': '154932', 'HookupDate': '2016-04-08', 'HookupTime': '11:27:00'}, 'summary': {'HR':     Hour  Min  #QRS's  Min.  Ave.  Max.  Pauses\n",
      "0     11   33    3023    77    93   113       0\n",
      "1     12   60    5083    68    85   114       0\n",
      "2     13   59    5858    75    99   122       0\n",
      "3     14   55    5003    69    91   109       0\n",
      "4     15   59    5768    74    98   133       0\n",
      "5     16   58    5985    70   102   138       0\n",
      "6     17   60    4595    64    77    93       0\n",
      "7     18   60    5137    75    86   111       0\n",
      "8     19   60    5420    80    91   106       0\n",
      "9     20   60    5259    78    88   100       0\n",
      "10    21   60    4674    69    78    90       0\n",
      "11    22   59    4580    64    77    93       0\n",
      "12    23   59    3891    56    66    94       0\n",
      "13     0   58    4111    57    70   106       0\n",
      "14     1   60    3848    53    64    96       0\n",
      "15     2   60    3472    49    58    88       0\n",
      "16     3   58    3955    48    68   103       0\n",
      "17     4   58    3910    49    68    97       0\n",
      "18     5   59    4029    52    68   102       0\n",
      "19     6   56    4279    59    75   106       0\n",
      "20     7   58    4036    51    69    87       0\n",
      "21     8   59    4924    62    83   109       0\n",
      "22     9   20    1542    63    78   111       0, 'VT':     Hour  Min  V_Iso  V_Cplt  V_Runs  V_Max_Run  V_Max_Rate\n",
      "0     11   33      0       0       0          0           0\n",
      "1     12   60      0       0       0          0           0\n",
      "2     13   59      1       0       0          0           0\n",
      "3     14   55      0       0       0          0           0\n",
      "4     15   59     14       0       0          0           0\n",
      "5     16   58      0       0       0          0           0\n",
      "6     17   60      1       0       0          0           0\n",
      "7     18   60      0       0       0          0           0\n",
      "8     19   60      0       0       0          0           0\n",
      "9     20   60      0       0       0          0           0\n",
      "10    21   60      0       0       0          0           0\n",
      "11    22   59      0       0       0          0           0\n",
      "12    23   59      0       0       0          0           0\n",
      "13     0   58      0       0       0          0           0\n",
      "14     1   60      0       0       0          0           0\n",
      "15     2   60      0       0       0          0           0\n",
      "16     3   58      0       0       0          0           0\n",
      "17     4   58      0       0       0          0           0\n",
      "18     5   59      0       0       0          0           0\n",
      "19     6   56      0       0       0          0           0\n",
      "20     7   58      0       0       0          0           0\n",
      "21     8   59      1       0       0          0           0\n",
      "22     9   20      0       0       0          0           0, 'SVT':     Hour  Min  S_Iso  S_Cplt  S_Runs  S_Max_Run  S_Max_Rate\n",
      "0     11   33      0       0       0          0           0\n",
      "1     12   60      3       0       0          0           0\n",
      "2     13   59      0       0       0          0           0\n",
      "3     14   55      3       0       0          0           0\n",
      "4     15   59      4       0       0          0           0\n",
      "5     16   58      2       0       0          0           0\n",
      "6     17   60      1       0       0          0           0\n",
      "7     18   60      0       0       0          0           0\n",
      "8     19   60      0       0       0          0           0\n",
      "9     20   60      1       0       0          0           0\n",
      "10    21   60      0       0       0          0           0\n",
      "11    22   59     21       0       0          0           0\n",
      "12    23   59    204       0       0          0           0\n",
      "13     0   58      6       0       0          0           0\n",
      "14     1   60      3       0       0          0           0\n",
      "15     2   60      2       0       0          0           0\n",
      "16     3   58      1       0       0          0           0\n",
      "17     4   58      1       0       0          0           0\n",
      "18     5   59      0       0       0          0           0\n",
      "19     6   56      1       0       0          0           0\n",
      "20     7   58      0       0       0          0           0\n",
      "21     8   59      1       1       0          0           0\n",
      "22     9   20      1       0       0          0           0}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Path to the pickle file\n",
    "pickle_file_path = r'D:\\test\\2224_141_154932.pickle'\n",
    "\n",
    "# Open the pickle file and load the data\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Now 'data' holds the deserialized content of the pickle file\n",
    "print(data)  # You can print or further manipulate 'data'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
