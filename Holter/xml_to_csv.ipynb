{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### holter_data.csv 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files in C:\\xml: 100%|██████████| 4/4 [00:00<00:00, 981.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows before removing: 0\n",
      "Number of duplicate rows after removing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_xml(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    data = {}\n",
    "    for elem in root.iter():\n",
    "        # Skip 'HolterReport' and 'PatientInfo' tags\n",
    "        if elem.tag in ['HolterReport', 'PatientInfo']:\n",
    "            continue\n",
    "        if elem.text:\n",
    "            text = elem.text.strip()\n",
    "            # Replace 'Unknown' with an empty string\n",
    "            if text == 'Unknown':\n",
    "                text = ''\n",
    "            # Convert date format\n",
    "            try:\n",
    "                text = datetime.strptime(text, '%d-%b-%Y').strftime('%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                pass\n",
    "            data[elem.tag] = text\n",
    "    \n",
    "    return data\n",
    "\n",
    "def extract_xml_data(directory):\n",
    "    all_data = []\n",
    "    xml_files = glob.glob(os.path.join(directory, '*.xml'))\n",
    "    for file_path in tqdm(xml_files, desc=f\"Processing files in {directory}\"):\n",
    "        data = parse_xml(file_path)\n",
    "        data['filename'] = os.path.basename(file_path)  # Add filename to data\n",
    "        all_data.append(data)\n",
    "    return all_data\n",
    "\n",
    "def main():\n",
    "    xml_directory = 'C:\\\\xml'\n",
    "\n",
    "    xml_data = extract_xml_data(xml_directory)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(xml_data)\n",
    "\n",
    "    # Rename 'PID' to 'cdm_id'\n",
    "    df = df.rename(columns={'PID': 'cdm_id'})\n",
    "\n",
    "    # Reorder columns to place 'filename' as the second column\n",
    "    cols = list(df.columns)\n",
    "    cols.insert(1, cols.pop(cols.index('filename')))\n",
    "    df = df[cols]\n",
    "\n",
    "    # Count duplicates before removing\n",
    "    initial_count = df.duplicated(subset=['cdm_id', 'HookupDate']).sum()\n",
    "    print(f'Number of duplicate rows before removing: {initial_count}')\n",
    "\n",
    "    # Remove duplicates based on 'cdm_id' and 'HookupDate'\n",
    "    df = df.drop_duplicates(subset=['cdm_id', 'HookupDate'], keep='last')\n",
    "\n",
    "    # Count duplicates after removing to confirm\n",
    "    final_count = df.duplicated(subset=['cdm_id', 'HookupDate']).sum()\n",
    "    print(f'Number of duplicate rows after removing: {final_count}')\n",
    "\n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv('C:\\\\xml\\\\holter_data.csv', index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
