{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PID to CDM_ID File Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:   5%|▍         | 225/4632 [00:00<00:01, 2209.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 40016_09040928.hea\n",
      "Error processing file: 40016_09040928.pdf\n",
      "Error processing file: 40016_09040928.SIG\n",
      "Error processing file: 40213_09105609.hea\n",
      "Error processing file: 40213_09105609.pdf\n",
      "Error processing file: 40213_09105609.SIG\n",
      "Error processing file: 40402_07768718.hea\n",
      "Error processing file: 40402_07768718.pdf\n",
      "Error processing file: 40402_07768718.SIG\n",
      "Error processing file: 40500_07746794.hea\n",
      "Error processing file: 40500_07746794.pdf\n",
      "Error processing file: 40500_07746794.SIG\n",
      "Error processing file: 40511_09128789.hea\n",
      "Error processing file: 40511_09128789.pdf\n",
      "Error processing file: 40511_09128789.SIG\n",
      "Error processing file: 40691_52171019.hea\n",
      "Error processing file: 40691_52171019.pdf\n",
      "Error processing file: 40691_52171019.SIG\n",
      "Error processing file: 40710_08492797.hea\n",
      "Error processing file: 40710_08492797.pdf\n",
      "Error processing file: 40710_08492797.SIG\n",
      "Error processing file: 40715_08634779.hea\n",
      "Error processing file: 40715_08634779.pdf\n",
      "Error processing file: 40715_08634779.SIG\n",
      "Error processing file: 41215_09225635.hea\n",
      "Error processing file: 41215_09225635.pdf\n",
      "Error processing file: 41215_09225635.SIG\n",
      "Error processing file: 41414_41049045.hea\n",
      "Error processing file: 41414_41049045.pdf\n",
      "Error processing file: 41414_41049045.SIG\n",
      "Error processing file: 41547_09310108.hea\n",
      "Error processing file: 41547_09310108.pdf\n",
      "Error processing file: 41547_09310108.SIG\n",
      "Error processing file: 41942_09590315.hea\n",
      "Error processing file: 41942_09590315.pdf\n",
      "Error processing file: 41942_09590315.SIG\n",
      "Error processing file: 41944_34416489.hea\n",
      "Error processing file: 41944_34416489.pdf\n",
      "Error processing file: 41944_34416489.SIG\n",
      "Error processing file: 42135_48875905.hea\n",
      "Error processing file: 42135_48875905.pdf\n",
      "Error processing file: 42135_48875905.SIG\n",
      "Error processing file: 42216_09295595.hea\n",
      "Error processing file: 42216_09295595.pdf\n",
      "Error processing file: 42216_09295595.SIG\n",
      "Error processing file: 42575_08492797.hea\n",
      "Error processing file: 42575_08492797.pdf\n",
      "Error processing file: 42575_08492797.SIG\n",
      "Error processing file: 43215_9899005.hea\n",
      "Error processing file: 43215_9899005.pdf\n",
      "Error processing file: 43215_9899005.SIG\n",
      "Error processing file: 43280_08325260.hea\n",
      "Error processing file: 43280_08325260.pdf\n",
      "Error processing file: 43280_08325260.SIG\n",
      "Error processing file: 43447_09681211.hea\n",
      "Error processing file: 43447_09681211.pdf\n",
      "Error processing file: 43447_09681211.SIG\n",
      "Error processing file: 43467_08203144.hea\n",
      "Error processing file: 43467_08203144.pdf\n",
      "Error processing file: 43467_08203144.SIG\n",
      "Error processing file: 43757_07726358.hea\n",
      "Error processing file: 43757_07726358.pdf\n",
      "Error processing file: 43757_07726358.SIG\n",
      "Error processing file: 43963_26099464.hea\n",
      "Error processing file: 43963_26099464.pdf\n",
      "Error processing file: 43963_26099464.SIG\n",
      "Error processing file: 43975_49612604.hea\n",
      "Error processing file: 43975_49612604.pdf\n",
      "Error processing file: 43975_49612604.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  13%|█▎        | 611/4632 [00:00<00:03, 1031.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 44036_09291740.hea\n",
      "Error processing file: 44036_09291740.pdf\n",
      "Error processing file: 44036_09291740.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  20%|██        | 929/4632 [00:00<00:04, 838.95it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 44135_08696809.hea\n",
      "Error processing file: 44135_08696809.pdf\n",
      "Error processing file: 44135_08696809.SIG\n",
      "Error processing file: 44189_08264853.hea\n",
      "Error processing file: 44189_08264853.pdf\n",
      "Error processing file: 44189_08264853.SIG\n",
      "Error processing file: 44202_08264853.hea\n",
      "Error processing file: 44202_08264853.pdf\n",
      "Error processing file: 44202_08264853.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  34%|███▎      | 1555/4632 [00:01<00:02, 1281.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 44296_09769919.hea\n",
      "Error processing file: 44296_09769919.pdf\n",
      "Error processing file: 44296_09769919.SIG\n",
      "Error processing file: 44343_09187360.hea\n",
      "Error processing file: 44343_09187360.pdf\n",
      "Error processing file: 44343_09187360.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  44%|████▎     | 2019/4632 [00:01<00:01, 1414.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 44489_32105789.hea\n",
      "Error processing file: 44489_32105789.pdf\n",
      "Error processing file: 44489_32105789.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  63%|██████▎   | 2903/4632 [00:02<00:01, 1334.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 44810_75157856.hea\n",
      "Error processing file: 44810_75157856.pdf\n",
      "Error processing file: 44810_75157856.SIG\n",
      "Error processing file: 44822_09040928.hea\n",
      "Error processing file: 44822_09040928.pdf\n",
      "Error processing file: 44822_09040928.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  81%|████████  | 3737/4632 [00:02<00:00, 1564.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 45109_09722237.hea\n",
      "Error processing file: 45109_09722237.pdf\n",
      "Error processing file: 45109_09722237.SIG\n",
      "Error processing file: 45135_07768718.hea\n",
      "Error processing file: 45135_07768718.pdf\n",
      "Error processing file: 45135_07768718.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  87%|████████▋ | 4036/4632 [00:03<00:00, 1331.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 45229_08098474.hea\n",
      "Error processing file: 45229_08098474.pdf\n",
      "Error processing file: 45229_08098474.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  97%|█████████▋| 4470/4632 [00:03<00:00, 1345.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 45377_26594568.hea\n",
      "Error processing file: 45377_26594568.pdf\n",
      "Error processing file: 45377_26594568.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files: 100%|██████████| 4632/4632 [00:03<00:00, 1264.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task completed. A total of 4515 files were converted and moved to c:\\old_rename.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:   5%|▌         | 792/14764 [08:38<3:08:54,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 41547_09310108.hea\n",
      "Error processing file: 41547_09310108.pdf\n",
      "Error processing file: 41547_09310108.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  13%|█▎        | 1963/14764 [21:38<1:15:09,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 41942_09590315.hea\n",
      "Error processing file: 41942_09590315.pdf\n",
      "Error processing file: 41942_09590315.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  13%|█▎        | 1969/14764 [21:40<1:03:00,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 41944_34416489.hea\n",
      "Error processing file: 41944_34416489.pdf\n",
      "Error processing file: 41944_34416489.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  17%|█▋        | 2533/14764 [27:53<1:07:03,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 42135_48875905.hea\n",
      "Error processing file: 42135_48875905.pdf\n",
      "Error processing file: 42135_48875905.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  19%|█▉        | 2770/14764 [30:28<1:09:14,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 42216_09295595.hea\n",
      "Error processing file: 42216_09295595.pdf\n",
      "Error processing file: 42216_09295595.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  26%|██▌       | 3796/14764 [41:59<1:04:05,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file: 42575_08492797.hea\n",
      "Error processing file: 42575_08492797.pdf\n",
      "Error processing file: 42575_08492797.SIG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Renaming files:  28%|██▊       | 4195/14764 [46:36<1:57:25,  1.50it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m         new_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(rename_dir, new_filename)\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;66;03m# 파일 복사\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m         \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m         converted_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\shutil.py:423\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    422\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 423\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\shutil.py:280\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Windows, see:\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# https://github.com/python/cpython/pull/7160#discussion_r195405230\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _WINDOWS \u001b[38;5;129;01mand\u001b[39;00m file_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 280\u001b[0m     \u001b[43m_copyfileobj_readinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOPY_BUFSIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[0;32m    283\u001b[0m copyfileobj(fsrc, fdst)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\shutil.py:194\u001b[0m, in \u001b[0;36m_copyfileobj_readinto\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shutil  # 파일 복사를 위해 shutil 모듈 사용\n",
    "\n",
    "# 경로 설정\n",
    "csv_path = r'C:\\github\\CDM\\Holter\\holter_pid.csv'\n",
    "file_dir = r'C:\\old_sig'\n",
    "rename_dir = r'c:\\old_rename'\n",
    "\n",
    "# old_rename 폴더가 없으면 생성\n",
    "if not os.path.exists(rename_dir):\n",
    "    os.makedirs(rename_dir)\n",
    "\n",
    "# CSV 파일 로드 및 딕셔너리 생성\n",
    "df = pd.read_csv(csv_path)\n",
    "pid_to_cdm_id = df.set_index('pid')['cdm_id'].to_dict()\n",
    "\n",
    "# 파일 리스트 가져오기\n",
    "files = [f for f in os.listdir(file_dir) if '_' in f]\n",
    "\n",
    "converted_count = 0\n",
    "\n",
    "# 파일 이름 변경 및 복사\n",
    "for file in tqdm(files, desc=\"Renaming files\"):\n",
    "    try:\n",
    "        parts = file.split('_')\n",
    "        index_number, pid = parts[0], parts[1].split('.')[0]  # 파일명에서 인덱스 번호와 pid 추출\n",
    "        extension = parts[1].split('.')[1]  # 파일 확장자 추출\n",
    "        cdm_id = pid_to_cdm_id.get(int(pid))  # pid에 대응하는 cdm_id 찾기\n",
    "\n",
    "        if cdm_id:\n",
    "            # cdm_id를 사용해 새로운 파일명 생성\n",
    "            new_filename = f'{index_number}_{int(cdm_id)}.{extension}'  \n",
    "\n",
    "            old_file_path = os.path.join(file_dir, file)\n",
    "            new_file_path = os.path.join(rename_dir, new_filename)\n",
    "            # 파일 복사\n",
    "            shutil.copy(old_file_path, new_file_path)\n",
    "            converted_count += 1  \n",
    "    except ValueError:\n",
    "        print(f'Error processing file: {file}')\n",
    "\n",
    "print(f'Task completed. A total of {converted_count} files were converted and copied to {rename_dir}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update .hea Filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10434 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10434/10434 [00:02<00:00, 3547.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of converted files: 3468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def replace_filename_in_hea_files(directory):\n",
    "    converted_files_count = 0\n",
    "    \n",
    "    # Traverse the directory and find .hea files\n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.hea'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    lines = file.readlines()\n",
    "                \n",
    "                # Modify the line\n",
    "                base_filename = filename.replace('.hea', '')\n",
    "                lines[0] = lines[0].replace(lines[0].split()[0], base_filename)\n",
    "                \n",
    "                for i in range(1, len(lines)):\n",
    "                    lines[i] = lines[i].replace(lines[i].split()[0], f\"{base_filename}.SIG\")\n",
    "                \n",
    "                with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                    file.writelines(lines)\n",
    "                \n",
    "                converted_files_count += 1\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file: {filename}. Error: {e}\")\n",
    "    \n",
    "    print(f\"Total number of converted files: {converted_files_count}\")\n",
    "\n",
    "directory_path = r'C:\\old_rename'\n",
    "replace_filename_in_hea_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report to XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process PDF files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDF Files:   8%|▊         | 273/3495 [00:04<00:42, 75.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process 40289_2217257.pdf: Cannot open empty file: filename='C:\\\\old_rename\\\\40289_2217257.pdf'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDF Files:  10%|▉         | 341/3495 [00:05<00:47, 66.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process 40356_2058072.pdf: Failed to open file 'C:\\\\old_rename\\\\40356_2058072.pdf'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDF Files:  32%|███▏      | 1104/3495 [00:14<00:32, 72.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process 42714_3708617.pdf: Failed to open file 'C:\\\\old_rename\\\\42714_3708617.pdf'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDF Files: 100%|██████████| 3495/3495 [00:43<00:00, 79.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to process the following files:\n",
      "40289_2217257.pdf\n",
      "40356_2058072.pdf\n",
      "42714_3708617.pdf\n",
      "Completed processing all files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "from xml.etree.ElementTree import Element, SubElement, tostring\n",
    "from xml.dom.minidom import parseString\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_match(pattern, text, default=\"Unknown\"):\n",
    "    match = re.search(pattern, text)\n",
    "    return match.group(1) if match else default\n",
    "\n",
    "def extract_grouped_matches(pattern, text, groups, default=\"Unknown\"):\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return [match.group(i + 1) for i in range(groups)]\n",
    "    return [default] * groups\n",
    "\n",
    "def parse_general_section(text):\n",
    "    general_section = re.search(r\"General\\n(.+?)Heart Rates\", text, re.DOTALL)\n",
    "    if general_section:\n",
    "        general_text = general_section.group(1)\n",
    "        qrs_complexes = extract_match(r\"(\\d+) QRS complexes\", general_text)\n",
    "        ventricular_beats = extract_match(r\"(\\d+) Ventricular beats\", general_text)\n",
    "        supraventricular_beats = extract_match(r\"(\\d+) Supraventricular beats\", general_text)\n",
    "        noise_percentage = extract_match(r\"(<\\s*\\d+|\\d+) % of total time classified as noise\", general_text, \"0\")\n",
    "        paced_beats = extract_match(r\"(\\d+) Paced beats\", general_text)\n",
    "        af_afl_percentage = extract_match(r\"(<\\s*\\d+|\\d+) % of total time in AF/AFL\", general_text)\n",
    "        bb_beats = extract_match(r\"(\\d+) BB beats\", general_text)\n",
    "        junctional_beats = extract_match(r\"(\\d+) Junctional beats\", general_text)\n",
    "        aberrant_beats = extract_match(r\"(\\d+) Aberrant beats\", general_text)\n",
    "    else:\n",
    "        qrs_complexes = ventricular_beats = supraventricular_beats = noise_percentage = \"Unknown\"\n",
    "        paced_beats = af_afl_percentage = bb_beats = junctional_beats = aberrant_beats = \"Unknown\"\n",
    "    return {\n",
    "        'QRScomplexes': qrs_complexes,\n",
    "        'VentricularBeats': ventricular_beats,\n",
    "        'SupraventricularBeats': supraventricular_beats,\n",
    "        'NoisePercentage': noise_percentage,\n",
    "        'PacedBeats': paced_beats,\n",
    "        'AFAFLPercentage': af_afl_percentage,\n",
    "        'BBBeats': bb_beats,\n",
    "        'JunctionalBeats': junctional_beats,\n",
    "        'AberrantBeats': aberrant_beats\n",
    "    }\n",
    "\n",
    "def parse_heart_rates_section(text):\n",
    "    heart_rates_data = {}\n",
    "    patterns = [\n",
    "        (r\"(\\d+) Minimum at ([\\d:]+ \\d+-\\w+)\", 'MinimumRate', 'Timestamp'),\n",
    "        (r\"(\\d+) Average\", 'AverageRate', None),\n",
    "        (r\"(\\d+) Maximum at ([\\d:]+ \\d+-\\w+)\", 'MaximumRate', 'Timestamp'),\n",
    "        (r\"(\\d+)\\s*Beats in tachycardia \\(>=?\\d+\\s*bpm\\),\\s*(\\d+)% total\", 'TachycardiaBeats', 'TachycardiaPercentage'),\n",
    "        (r\"(\\d+)\\s*Beats in bradycardia \\(<=?\\d+\\s*bpm\\),\\s*(\\d+)% total\", 'BradycardiaBeats', 'BradycardiaPercentage')\n",
    "    ]\n",
    "    for pattern, main_tag, sub_tag in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            heart_rates_data[main_tag] = (match.group(1), match.group(2) if sub_tag else None)\n",
    "        else:\n",
    "            heart_rates_data[main_tag] = (\"Unknown\", \"Unknown\" if sub_tag else None)\n",
    "    return heart_rates_data\n",
    "\n",
    "def parse_section(section_text, patterns):\n",
    "    section_data = {}\n",
    "    for pattern, tags in patterns:\n",
    "        matches = extract_grouped_matches(pattern, section_text, len(tags))\n",
    "        for tag_index, tag in enumerate(tags):\n",
    "            section_data[tag] = matches[tag_index]\n",
    "    return section_data\n",
    "\n",
    "def create_xml(patient_info, general_data, heart_rates_data, ventriculars_data, supraventriculars_data, xml_path):\n",
    "    root = Element('HolterReport')\n",
    "    patient_info_element = SubElement(root, 'PatientInfo')\n",
    "    for key, value in patient_info.items():\n",
    "        SubElement(patient_info_element, key).text = value\n",
    "\n",
    "    general_element = SubElement(root, 'General')\n",
    "    for key, value in general_data.items():\n",
    "        SubElement(general_element, key).text = value\n",
    "\n",
    "    heart_rates_element = SubElement(root, 'HeartRates')\n",
    "    for key, (value, sub_value) in heart_rates_data.items():\n",
    "        element = SubElement(heart_rates_element, key)\n",
    "        if sub_value:\n",
    "            SubElement(element, 'Timestamp').text = sub_value\n",
    "        element.text = value\n",
    "\n",
    "    ventriculars_element = SubElement(root, 'Ventriculars')\n",
    "    for key, value in ventriculars_data.items():\n",
    "        SubElement(ventriculars_element, key).text = value\n",
    "\n",
    "    supraventriculars_element = SubElement(root, 'Supraventriculars')\n",
    "    for key, value in supraventriculars_data.items():\n",
    "        SubElement(supraventriculars_element, key).text = value\n",
    "\n",
    "    xml_str = tostring(root, 'utf-8')\n",
    "    parsed_str = parseString(xml_str)\n",
    "    pretty_xml_str = parsed_str.toprettyxml(indent=\"   \")\n",
    "\n",
    "    with open(xml_path, \"w\") as xml_file:\n",
    "        xml_file.write(pretty_xml_str)\n",
    "\n",
    "def process_pdf_files(file_dirs, xml_dir):\n",
    "    pdf_files = []\n",
    "    for file_dir in file_dirs:\n",
    "        for root, _, files in os.walk(file_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.pdf'):\n",
    "                    pdf_files.append(os.path.join(root, file))\n",
    "    \n",
    "    failed_files = []\n",
    "\n",
    "    for pdf_path in tqdm(pdf_files, desc=\"Processing PDF Files\"):\n",
    "        try:\n",
    "            filename = os.path.basename(pdf_path)\n",
    "            pdf_doc = fitz.open(pdf_path)\n",
    "            page = pdf_doc.load_page(0)\n",
    "            extracted_text = page.get_text()\n",
    "\n",
    "            patient_info = {\n",
    "                'PID': extract_match(r\"Patient Name:?\\n(\\d+)\\nID:?\", extracted_text, filename.split('_')[-1].replace('.pdf', '')),\n",
    "                'HookupDate': extract_match(r\"Medications:?\\n(\\d+-\\w+-\\d+)\\nHookup Date:?\", extracted_text, \"Unknown\"),\n",
    "                'HookupTime': extract_match(r\"Hookup Date:?\\n(\\d+:\\d+:\\d+)\\nHookup Time:?\", extracted_text, \"Unknown\"),\n",
    "                'Duration': extract_match(r\"Hookup Time:?\\n(\\d+:\\d+:\\d+)\\nDuration:?\", extracted_text, \"Unknown\"),\n",
    "                'Age': extract_match(r\"(\\d+)\\s*yr\\s*Age:\", extracted_text, \"Unknown\"),\n",
    "                'Gender': extract_match(r\"(Male|Female)\\s*Gender:\", extracted_text, \"Unknown\")\n",
    "            }\n",
    "\n",
    "            general_data = parse_general_section(extracted_text)\n",
    "\n",
    "            heart_rates_data = parse_heart_rates_section(extracted_text)\n",
    "\n",
    "            ventriculars_section = extract_match(r\"Ventriculars \\(V, F, E, I\\)\\n([\\s\\S]+?)\\nSupraventriculars \\(S, J, A\\)\", extracted_text, \"\")\n",
    "            supraventriculars_section = extract_match(r\"Supraventriculars \\(S, J, A\\)\\n([\\s\\S]+?)Interpretation\", extracted_text, \"\")\n",
    "\n",
    "            ventriculars_patterns = [\n",
    "                (r\"(\\d+) Isolated\", ['Isolated']),\n",
    "                (r\"(\\d+) Couplets\", ['Couplets']),\n",
    "                (r\"(\\d+) Bigeminal cycles\", ['BigeminalCycles']),\n",
    "                (r\"(\\d+) Runs totaling (\\d+) beats\", ['Runs', 'TotalBeats']),\n",
    "                (r\"(\\d+) Beats longest run (\\d+) bpm ([\\d:]+ \\d+-\\w+)\", ['LongestRunBeats', 'LongestRunBPM', 'LongestRunTimestamp']),\n",
    "                (r\"(\\d+) Beats fastest run (\\d+) bpm ([\\d:]+ \\d+-\\w+)\", ['FastestRunBeats', 'FastestRunBPM', 'FastestRunTimestamp'])\n",
    "            ]\n",
    "\n",
    "            supraventriculars_patterns = [\n",
    "                (r\"(\\d+) Isolated\", ['Isolated']),\n",
    "                (r\"(\\d+) Couplets\", ['Couplets']),\n",
    "                (r\"(\\d+) Bigeminal cycles\", ['BigeminalCycles']),\n",
    "                (r\"(\\d+) Runs totaling (\\d+) beats\", ['Runs', 'TotalBeats']),\n",
    "                (r\"(\\d+) Beats longest run (\\d+) bpm ([\\d:]+ \\d+-\\w+)\", ['LongestRunBeats', 'LongestRunBPM', 'LongestRunTimestamp']),\n",
    "                (r\"(\\d+) Beats fastest run (\\d+) bpm ([\\d:]+ \\d+-\\w+)\", ['FastestRunBeats', 'FastestRunBPM', 'FastestRunTimestamp'])\n",
    "            ]\n",
    "\n",
    "            ventriculars_data = parse_section(ventriculars_section, ventriculars_patterns)\n",
    "            supraventriculars_data = parse_section(supraventriculars_section, supraventriculars_patterns)\n",
    "\n",
    "            xml_path = os.path.join(xml_dir, os.path.splitext(filename)[0] + '.xml')\n",
    "            create_xml(patient_info, general_data, heart_rates_data, ventriculars_data, supraventriculars_data, xml_path)\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {filename}: {e}\")\n",
    "            failed_files.append(filename)\n",
    "\n",
    "    return failed_files\n",
    "\n",
    "def main():\n",
    "    base_dirs = [\n",
    "        r'C:\\old_rename'\n",
    "    ]\n",
    "    xml_dir = r'C:\\old_rename'\n",
    "\n",
    "    if not os.path.exists(xml_dir):\n",
    "        os.makedirs(xml_dir)\n",
    "\n",
    "    print(\"Starting to process PDF files...\")\n",
    "    failed_files_record = process_pdf_files(base_dirs, xml_dir)\n",
    "\n",
    "    if failed_files_record:\n",
    "        print(\"\\nFailed to process the following files:\")\n",
    "        for failed_file in failed_files_record:\n",
    "            print(failed_file)\n",
    "    else:\n",
    "        print(\"\\nAll PDF files processed successfully.\")\n",
    "\n",
    "    print(\"Completed processing all files.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XML 파일을 읽고, PID 값을 파일명에 있는 값으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing XML files: 100%|██████████| 3492/3492 [00:10<00:00, 341.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 XML 파일의 PID 값이 변경되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 폴더 경로\n",
    "folder_path = r'C:\\old_rename'\n",
    "\n",
    "# 폴더 내의 모든 XML 파일을 확인\n",
    "xml_files = [file for file in os.listdir(folder_path) if file.endswith('.xml')]\n",
    "\n",
    "# tqdm을 사용하여 진행 상황 표시\n",
    "for file_name in tqdm(xml_files, desc=\"Processing XML files\"):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # 파일명에서 '_' 뒤의 값을 추출\n",
    "    new_pid = file_name.split('_')[-1].split('.')[0]\n",
    "    \n",
    "    # XML 파일 로드\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # PID 태그를 찾고 값을 새로운 PID로 변경\n",
    "    for pid in root.iter('PID'):\n",
    "        pid.text = new_pid\n",
    "    \n",
    "    # 변경된 XML을 파일에 다시 저장\n",
    "    tree.write(file_path)\n",
    "\n",
    "print(\"모든 XML 파일의 PID 값이 변경되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
